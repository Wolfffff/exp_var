# Simple script showing how to pull data from Expression Atlas and recount3, normalize, and remove batch effects.

```{r setup, include=FALSE}
library(ExpressionAtlas)
library(plyr)
library(tidyverse)
library(limma)
library(sva)
library(edgeR)
library(ggplot2)
library(janitor)
library(foreach)
library(doParallel)
library(biomaRt)
library(ggfortify)
library(patchwork)
library(cowplot)
library(clusterProfiler)
library(AnnotationDbi)
#pak::pkg_install(c("rrcov", "org.Hs.eg.db"))
library(org.Hs.eg.db)
library(rrcov)

source("functions.R")

# Set timeout to avoid failure when trying to download GTEx or other large datasets
options(timeout = 1800)
```

```{r}
experimental_metadata_ea <- read_csv("expression_atlas_metadata.csv")
experimental_metadata_ea <- experimental_metadata_ea[-1,] # Remove the top row (GTEx) to lower the time cost when testing

# Load metadata from recount3
experimental_metadata_rc3 <- read_csv("recount3_metadata.csv")


plots_dir <- "data/"

# Setup filters for removing samples accordingly to the metadata
feature_vec <- list()
feature_vec[["disease"]] <- c("normal", "control", "", NA, 
                              "non inflammatory bowel disease control")
feature_vec[["treatment"]] <- c("normal", "control", "", NA)
```

## recount3

```{r recount3}
# This is commented out as we're sticking with Expression Atlas for now.
library(recount3)

# Move cache to deal with quota issues
cache = recount3_cache(cache_dir="cache")
human_projects <- available_projects(bfc=cache)

exp_data_rc3 = list()
# recount_cache_rm()
for (id in experimental_metadata_rc3$id) {
  # Load the project
  proj_info <- subset(
    human_projects,
    project == id & project_type == "data_sources"
  )
  # Tape to deal with acquisition issues
  rse <- create_rse(proj_info, bfc=cache)
  if (proj_info$file_source == "gtex") {
    metadata_df <- colData(rse)[,grepl("gtex",colnames(colData(rse)),fixed=TRUE)]
  } else {
    #Could probably just use expand_sra_attributes
    metadata_df <- convert_metadata_to_df_rc3(colData(rse)$sra.sample_attributes)
  }
  
  # Crude way to set NA to ""
  metadata_df@listData <- lapply(metadata_df@listData, function(x) {
    x[is.na(x)] = ""
    x
  })

  rse@colData <- metadata_df
  exp_data_rc3[[id]] <- rse
}
```

## Expression Atlas

```{r}
accession_ids <- experimental_metadata_ea$id

rnaseq_exps <- getAtlasData(accession_ids)

all_exps <- rnaseq_exps
exps <- names(rnaseq_exps@listData)

exp_data_ea <- lapply(exps, FUN = function(x) {
    return(all_exps[[x]]$rnaseq)
})
names(exp_data_ea) <- exps
```

## Main loop

```{r}
source("./main_processing_loop.R")
parallel = FALSE
if(.Platform$OS.type == "unix") {
  parallel = TRUE
  library(doMC)
  registerDoMC(32)
} 
results_list_ea <- llply(names(exp_data_ea), 
                      main_count_processing, 
                      exp_data_ea, 
                      experimental_metadata_ea, 
                      feature_vec,
                      assay_name="counts", 
                      .parallel = parallel)  
names(results_list_ea) <- names(exp_data_ea)
for(dset_name in names(results_list_ea)) 
  save_plot(filename=paste0(plots_dir, dset_name,"_pca.png"), results_list_ea[[dset_name]]$plotPanel, 
            base_height = 6, base_asp = 1.2, ncol = 2, nrow = 2)
save(results_list_ea, file = "results_list_ea.RData")
```

Add a second loop for processing recount3 data.

```{r}
source("./main_processing_loop.R")
parallel = FALSE
if(.Platform$OS.type == "unix") {
  parallel = TRUE
  library(doMC)
  registerDoMC(32)
} 

results_list_rc3 <- llply(names(exp_data_rc3), 
                      main_count_processing,  
                      exp_data = exp_data_rc3, 
                      experimental_metadata = experimental_metadata_rc3, 
                      feature_vec = feature_vec,
                      assay_name = "raw_counts", 
                      .parallel = parallel)  

names(results_list_rc3) <- names(exp_data_rc3)
                    
for(dset_name in names(results_list_rc3)) 
  save_plot(filename=paste0(plots_dir, dset_name,"_pca.png"), results_list_rc3[[dset_name]]$plotPanel, 
            base_height = 6, base_asp = 1.2, ncol = 2, nrow = 2)

save(results_list_rc3, file = "results_list_rc3.RData")
```

Now we calculate the gene expression variance in all the datasets.

```{r}
variance_df_list = vector("list", length = length(results_list_ea))
names(variance_df_list) = names(results_list_ea)
for (dset_name in names(results_list_ea)) {
  print(dset_name)
  exprDf = results_list_ea[[dset_name]]
  gene_vars = rowVars(exprDf$residuals)
  variance_df_list[[dset_name]] = data.frame(
      Genes = names(gene_vars),
      vars = gene_vars)
  }
  variance_df = reduce(variance_df_list, inner_join, by = "Genes")
  colnames(variance_df)[-1] = names(results_list_ea)
```

Spearman correlations between the variances across datasets.

```{r}
pak::pkg_install("corrplot")
library(corrplot)
var_cor = cor(variance_df[,-1], method = "s")
png("data/var_corr_plot_EA.png", height = 1080, width = 1080)
corrplot.mixed(var_cor, upper = "ellipse")
dev.off()
```

Example of how to run a list of genes for biological process GO enrichment.
Here I'm taking the first 500 genes with the largest variance in the first dataset.

```{r}
top_genes = variance_df[order(variance_df[,2], decreasing = TRUE)[1:500],]

GO_enrichment = enrichGO(gene  = top_genes$Genes,
                         universe      = variance_df$Genes,
                         OrgDb         = org.Hs.eg.db,
                         keyType       = 'ENSEMBL',
                         ont           = "BP",
                         pAdjustMethod = "BH",
                         pvalueCutoff  = 0.01,
                         qvalueCutoff  = 0.05,
                         readable      = TRUE)
GO_enrichment@result %>% as_tibble %>% 
    filter(Count>10) %>% 
    arrange(p.adjust) %>%
    dplyr::select(ID, Description, Count, p.adjust) 
```